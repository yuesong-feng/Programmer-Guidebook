逻辑回归简单说就是线性回归加上一个Sigmoid函数。

y_predict = Sigmoid(W.T * X)

注意：是必须用Sigmoid函数，可以用严格的数学证明推导出来，而不是随意选择的一个函数。

重点：

1、 样本服从伯努利分布((0, 1)分布)

2、 损失函数是交叉熵损失函数，由来：伯努利分布的极大似然估计

求解模型参数W，可以使用梯度下降法，属于优化算法（牛顿法）。这里的梯度是指对损失函数的梯度。

梯度就是loss函数对于一个输入自变量的偏导数，新的参数w_t+1 = w_t - a * gradient(w)，其中a是步长（学习速率）。

推导如下：

推导。。。。。。

逻辑回归特征：喜欢独立、离散的特征，做文本分类、ctr预估等工作非常轻量、高效，特征是高维稀疏类别特征，故天然适用于ctr场景，离散化的原因是：鲁棒性，引入非线性。